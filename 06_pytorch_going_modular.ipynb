{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPqKDWmeDpZyU0dBt6a1Qnj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AH25XCFrxwUY","executionInfo":{"status":"ok","timestamp":1689831944507,"user_tz":-480,"elapsed":973,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}},"outputId":"f27c0b8a-0318-4469-8af7-2b5672659ffa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi directory, creating one...\n","Downloading...\n","Unzipping pizza, steak, sushi data...\n"]}],"source":["import os\n","import requests\n","import zipfile\n","from pathlib import Path\n","\n","data_path = Path('data/')\n","img_path = data_path/'pizza_steak_sushi'\n","\n","if img_path.is_dir():\n","  print(f'{img_path} directory exists.')\n","else:\n","  print(f'Did not find {img_path} directory, creating one...')\n","  img_path.mkdir(parents = True, exist_ok = True)\n","\n","with open(data_path/'pizza_steak_sushi.zip', 'wb') as f:\n","  rq = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n","  print('Downloading...')\n","  f.write(rq.content)\n","\n","with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n","  print('Unzipping pizza, steak, sushi data...')\n","  zip_ref.extractall(img_path)\n","\n","os.remove(data_path/'pizza_steak_sushi.zip')"]},{"cell_type":"code","source":["going_modular_dir = Path('data/going_modular')\n","if going_modular_dir.is_dir():\n","  print(f'{going_modular_dir} exists.')\n","else:\n","  going_modular_dir.mkdir(parents = True, exist_ok = True)"],"metadata":{"id":"_JiYTfJL8ew3","executionInfo":{"status":"ok","timestamp":1689833908656,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["%%writefile going_modular/data_setup.py\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","import os\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","  train_dir: str,\n","  test_dir: str,\n","  transform: transforms.Compose,\n","  batch_size: int,\n","  num_workers: int = NUM_WORKERS\n","):\n","\n","  train_data = datasets.ImageFolder(train_dir, transform = transform)\n","  test_data = datasets.ImageFolder(test_dir, transform = transform)\n","\n","  class_names = train_data.classes\n","\n","  train_dataloader = DataLoader(\n","    train_data,\n","    batch_size = batch_size,\n","    shuffle = True,\n","    num_workers = num_workers,\n","    pin_memory = True,\n","  )\n","\n","  test_dataloader = DataLoader(\n","    test_data,\n","    batch_size = batch_size,\n","    shuffle = True,\n","    num_workers = num_workers,\n","    pin_memory = True,\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJjT1ydy0QeW","executionInfo":{"status":"ok","timestamp":1689841346204,"user_tz":-480,"elapsed":333,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}},"outputId":"1762ae5d-9031-4144-dd7e-3c837f655e48"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/data_setup.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/model_builder.py\n","\n","import torch\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","    super().__init__()\n","    self.conv_block_1 = nn.Sequential(\n","        nn.Conv2d(in_channels = input_shape,\n","                  out_channels = hidden_units,\n","                  kernel_size = 3,\n","                  stride = 1,\n","                  padding = 0),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels = hidden_units,\n","                  out_channels = hidden_units,\n","                  kernel_size = 3,\n","                  stride = 1,\n","                  padding = 0),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size = 2,\n","                     stride = 2)\n","    )\n","    self.conv_block_2 = nn.Sequential(\n","        nn.Conv2d(hidden_units, hidden_units, kernel_size = 3, padding = 0),\n","        nn.ReLU(),\n","        nn.Conv2d(hidden_units, hidden_units, kernel_size = 3, padding = 0),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2)\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(in_features = hidden_units * 13 * 13,\n","                  out_features = output_shape)\n","    )\n","\n","  def forward(self, x: torch.Tensor):\n","    x = self.conv_block_1(x)\n","    x = self.conv_block_2(x)\n","    x = self.classifier(x)\n","    return x"],"metadata":{"id":"d_kqAyAw2QXa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689841348626,"user_tz":-480,"elapsed":384,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}},"outputId":"4525e113-8847-45ef-dd88-d34bef0f165b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/model_builder.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/engine.py\n","\n","import torch\n","\n","from tqdm.auto import tqdm\n","from typing import Dict, List, Tuple\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","  model.train()\n","  train_loss, train_acc = 0, 0\n","\n","  for batch, (X, y) in enumerate(dataloader):\n","    X, y = X.to(device), y.to(device)\n","\n","    y_pred = model(X)\n","\n","    loss = loss_fn(y_pred, y)\n","    train_loss += loss.item()\n","\n","    optimizer.zero_grad()\n","\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    y_pred_class = torch.argmax(torch.softmax(y_pred, dim = 1), dim = 1)\n","    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","  train_loss = train_loss / len(dataloader)\n","  train_acc = train_acc / len(dataloader)\n","  return train_loss, train_acc\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","  model.eval()\n","  test_loss, test_acc = 0, 0\n","\n","  with torch.inference_mode():\n","    for batch, (X, y) in enumerate(dataloader):\n","      X, y = X.to(device), y.to(device)\n","      test_pred_logits = model(X)\n","\n","      loss = loss_fn(test_pred_logits, y)\n","      test_loss += loss.item()\n","\n","      test_pred_labels = test_pred_logits.argmax(dim = 1)\n","      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","  test_loss = test_loss/len(dataloader)\n","  test_acc = test_acc/len(dataloader)\n","  return test_loss, test_acc\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List]:\n","\n","  results = {'train_loss': [],\n","             'train_acc': [],\n","             'test_loss': [],\n","             'test_acc': []}\n","\n","  for epoch in tqdm(range(epochs)):\n","    train_loss, train_acc = train_step(model = model,\n","                                       dataloader = train_dataloader,\n","                                       loss_fn = loss_fn,\n","                                       optimizer = optimizer,\n","                                       device = device)\n","    test_loss, test_acc = test_step(model = model,\n","                                    dataloader = test_dataloader,\n","                                    loss_fn = loss_fn,\n","                                    device = device)\n","\n","    print(\n","        f\"Epoch: {epoch + 1} |\"\n","        f\"train_loss: {train_loss:.4f} |\"\n","        f\"train_acc: {train_acc:.4f} |\"\n","        f\"test_loss: {test_loss:.4f} |\"\n","        f\"test_acc: {test_acc:.4f}\"\n","    )\n","\n","    results['train_loss'].append(train_loss)\n","    results['train_acc'].append(train_acc)\n","    results['test_loss'].append(test_loss)\n","    results['test_acc'].append(test_acc)\n","\n","  return results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKDFaKIL-9U3","executionInfo":{"status":"ok","timestamp":1689842216754,"user_tz":-480,"elapsed":302,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}},"outputId":"8d3a2324-92f8-463d-81ca-cfcbc1a96c63"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/engine.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/utils.py\n","\n","import torch\n","from pathlib import Path\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","  target_dir_path = Path(target_dir)\n","  target_dir_path.mkdir(parents = True, exist_ok = True)\n","  assert model_name.endswith('.pth') or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","  model_save_path = target_dir_path/model_name\n","\n","  print(f\"[INFO] Saving model to {model_save_path}\")\n","  torch.save(obj = model.state_dict(),\n","             f = model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBRold9Bcbf4","executionInfo":{"status":"ok","timestamp":1689842563211,"user_tz":-480,"elapsed":403,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}},"outputId":"fda6c7f6-eac6-4ed4-e367-55d46aec0eea"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/utils.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/train.py\n","\"\"\"\n","Trains a PyTorch image classification model using device-agnostic code.\n","\"\"\"\n","\n","import os\n","import torch\n","import data_setup, engine, model_builder, utils\n","\n","from torchvision import transforms\n","\n","# Setup hyperparameters\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 32\n","HIDDEN_UNITS = 10\n","LEARNING_RATE = 0.001\n","\n","# Setup directories\n","train_dir = \"data/pizza_steak_sushi/train\"\n","test_dir = \"data/pizza_steak_sushi/test\"\n","\n","# Setup target device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create transforms\n","data_transform = transforms.Compose([\n","  transforms.Resize((64, 64)),\n","  transforms.ToTensor()\n","])\n","\n","# Create DataLoaders with help from data_setup.py\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transform=data_transform,\n","    batch_size=BATCH_SIZE\n",")\n","\n","# Create model with help from model_builder.py\n","model = model_builder.TinyVGG(\n","    input_shape=3,\n","    hidden_units=HIDDEN_UNITS,\n","    output_shape=len(class_names)\n",").to(device)\n","\n","# Set loss and optimizer\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),\n","                             lr=LEARNING_RATE)\n","\n","# Start training with help from engine.py\n","engine.train(model=model,\n","             train_dataloader=train_dataloader,\n","             test_dataloader=test_dataloader,\n","             loss_fn=loss_fn,\n","             optimizer=optimizer,\n","             epochs=NUM_EPOCHS,\n","             device=device)\n","\n","# Save the model with help from utils.py\n","utils.save_model(model=model,\n","                 target_dir=\"models\",\n","                 model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WO9E3EI9dxnT","executionInfo":{"status":"ok","timestamp":1689842786951,"user_tz":-480,"elapsed":475,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}},"outputId":"910f98cf-b8ec-4051-e1b6-12ae2e4ee062"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/train.py\n"]}]},{"cell_type":"code","source":["!python train.py"],"metadata":{"id":"9GmNKhgJep6x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the train.py file\n","os.system('python train.py --learning_rate 0.003 --batch_size 64 --num_epochs 20')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgTU3Lwkesu2","executionInfo":{"status":"ok","timestamp":1689843076064,"user_tz":-480,"elapsed":3245,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}},"outputId":"cd1959a8-a15a-4cfb-bcb9-dee3e21bff5d"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["256"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":[],"metadata":{"id":"-nhcE_aNfEYk"}},{"cell_type":"code","source":["os.chdir(cur_directory)"],"metadata":{"id":"DadiYKkxe8Ib","executionInfo":{"status":"ok","timestamp":1689843054653,"user_tz":-480,"elapsed":313,"user":{"displayName":"Jovan Chua","userId":"02891103034076238473"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SQ24C9TdftNT"},"execution_count":null,"outputs":[]}]}